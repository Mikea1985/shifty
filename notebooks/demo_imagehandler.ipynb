{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------------------\n",
    "# Third party imports\n",
    "# -------------------------------------------------------------------------------------\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import os, sys\n",
    "import glob \n",
    "\n",
    "import astropy\n",
    "from astropy.io import fits\n",
    "from astropy.time import Time\n",
    "from astropy.units import allclose as quantity_allclose\n",
    "from astropy import units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.coordinates.builtin_frames import FK5, ICRS, GCRS, GeocentricMeanEcliptic, BarycentricMeanEcliptic, HeliocentricMeanEcliptic, GeocentricTrueEcliptic, BarycentricTrueEcliptic, HeliocentricTrueEcliptic, HeliocentricEclipticIAU76\n",
    "from astropy.constants import R_sun, R_earth\n",
    "from astropy.nddata import CCDData\n",
    "\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "from ccdproc import Combiner\n",
    "from ccdproc import wcs_project\n",
    "\n",
    "import inspect\n",
    "import importlib\n",
    "\n",
    "# -------------------------------------------------------------------------------------\n",
    "# Local imports\n",
    "# -------------------------------------------------------------------------------------\n",
    "sys.path.append(os.path.join(os.path.split(os.getcwd())[0], 'shifty'))\n",
    "import downloader \n",
    "import refcat\n",
    "import imagehandler\n",
    "import known\n",
    "\n",
    "importlib.reload(downloader)\n",
    "importlib.reload(refcat)\n",
    "importlib.reload(imagehandler)\n",
    "importlib.reload(known)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OneImage\n",
    "This class exists for dealing with individual images. \n",
    "Currently its functionality is pretty limited, so I'm not convinced it needs to be a seperate class, as the functionality could just get rolled in to ImageEnsemble.\n",
    "But maybe we'll add more to it that will be valuable to have on a per-image basis.\n",
    "\n",
    "Start by initializing the class with a filename. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../dev_data/2015RS281_HSC20160826_123.fits'\n",
    "one=imagehandler.OneImage(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initialization can be given additional keywords:\n",
    "\n",
    "        extno          - int          - Extension number of image data\n",
    "                                      - (0 if single-extension)\n",
    "                                      - default is 0\n",
    "        verbose        - bool         - Print extra stuff if True\n",
    "                                      - default is False\n",
    "        EXPTIME        - str OR float - Exposure time in seconds\n",
    "                                      - (keyword or value)\n",
    "                                      - default is 'EXPTIME'\n",
    "        MAGZERO        - str OR float - Zeropoint magnitude\n",
    "                                      - (keyword or value)\n",
    "                                      - default is 'MAGZERO'\n",
    "        MJD_START      - str OR float - MJD at start of exposure\n",
    "                                      - (keyword or value)\n",
    "                                      - default is 'MJD-STR'\n",
    "        GAIN           - str OR float - Gain value (keyword or value)\n",
    "                                      - default is 'GAINEFF'\n",
    "        FILTER         - str          - Filter name (keyword)\n",
    "                                      - default is 'FILTER'\n",
    "        NAXIS1         - str OR int   - Number of pixels along axis 1\n",
    "                                      - default is 'NAXIS1'\n",
    "        NAXIS2         - str OR int   - Number of pixels along axis 2\n",
    "                                      - default is 'NAXIS2'\n",
    "        INSTRUMENT     - str          - Instrument name (keyword)\n",
    "                                      - default is 'INSTRUME'\n",
    "Most of this is probably not actually needed, but I figured that for now it would be good to have handy any header values that we _might_ need. \n",
    "\n",
    "The _one_ object should now have a few attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[key for key in one.__dict__.keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- _readOneImageAndHeader_ is the function used for reading a file. It's available here as a pseudo-method, in case a new file should get read in or the object was initialized without a filename.\n",
    "- _header_keywords_ is a dictionary connecting the specified names of keywords to their default names.\n",
    "- _key_values_ is a dictionary with the values of the header keywords\n",
    "- _WCS_ is the WCS\n",
    "- _header_ is the entire header of the image extension\n",
    "- _header0_ is the entire main header (multi-extension fits often have some info, like WCS, in individual extension headers and other info, like exposure time, in the main header in extension 0).\n",
    "- _data_ is a 2D numpy array with the pixel data\n",
    "- _filename_ remembers the input filename\n",
    "- _extno_ remembers the input extension number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"one.extno: {one.extno}\")\n",
    "print(f\"one.filename: {one.filename}\")\n",
    "print(f\"Data shape: {one.data.shape}, 3x3 cutout:\")\n",
    "print(one.data[81:84,81:84])\n",
    "print(\"\")\n",
    "print(one.WCS)\n",
    "print(f\"\\none.header_keywords content:\")\n",
    "_ = [print(o) for o in one.header_keywords.items()]\n",
    "print(f\"\\none.key_values content:\")\n",
    "_ = [print(o) for o in one.key_values.items()]\n",
    "plt.imshow((one.data-one.data.min())[520:720,405:605], origin='lower', cmap='gray',norm=LogNorm())\n",
    "cbar = plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataEnsemble\n",
    "This class is used for accumulating information about a whole set of associated images. \n",
    "It contains these methods:\n",
    "- reproject_data - for aligning (by reprojection) images to a shared WCS. Optional step.\n",
    "It is essentially a container for: a 3D data array, an array of WCS objects, and an array of header objects. This can be used for loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm gonna define this flag, so that it's easy to switch between\n",
    "# using both nights (24 images) and just the second night (12 images).\n",
    "# Only the last 12 images are in GitHub repo.\n",
    "both_nights=False\n",
    "#both_nights=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First make a list of filenames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(imagehandler)\n",
    "filename = '../dev_data/2015RS281_HSC20160826_112.fits'\n",
    "if both_nights:\n",
    "    filenames=[filename.replace('112', str(i)) for i in np.arange(100, 124)]\n",
    "    filenames[:12]=[filenamei.replace('0826', '0825') for filenamei in filenames[:12]]\n",
    "else:\n",
    "    filenames=[filename.replace('112', str(i)) for i in np.arange(112, 124)]\n",
    "\n",
    "filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize with the list of filenames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(imagehandler)\n",
    "E=imagehandler.DataEnsemble(filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initialization can be given the same additional keywords as OneImage. Additionally, _extno_ is allowed to be a list/array, in case the desired image isn't in the same extension for all images.\n",
    "\n",
    "The content of _E_ looks much the same as for _one_, but most of the attributes are now arrays (if they weren't already) with the additional dimension of having an entry per image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[key for key in E.__dict__.keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_E_ also have _reprojected_ attribute starting as False."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If neccessary, the data arrays can be reprojected (using ccdproc.wcs_project) so that the arrays have the same shared projection.\n",
    "This is slow (several minutes), and isn't neccessary if you're only interested in a small part of the field and the fact that the images are offset/warped relative to each other gets built into the shifts.\n",
    "The HSC images used here were reprojected previously, so we'll skip this here. If this step is run, the _.reprojected_ attribute gets set to _True_ and _.data_ is overwritten with the reprojected data. (Note to self: prevent _.reproject_data_ from running if _.reprojected==True_)\n",
    "It is probably unneccessary to reproject in most cases, as the offset between images can be accounted for using the calculated shifts later, so reprojection only makes sense if the curvature is large, in which case getting all the images on the same projection is useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#E.reproject_data() # Slow!\n",
    "print(E.reprojected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataHandler\n",
    "This class is used for handling the data. It contains several DataEnsemble objects within it, and methods for manipulating them.  \n",
    "These methods exist:\n",
    "- integer_shift - shift image data by an integer number of pixels. \n",
    "- stack - stacks all the data arrays, either shifted or non-shifted (keyword controlled).\n",
    "- save_stack - saves a stacked array to a fits file.\n",
    "- save_shift - saves the shifted arrays to fits files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm gonna define this flag, so that it's easy to switch between\n",
    "# using both nights (24 images) and just the second night (12 images).\n",
    "# Only the last 12 images are in GitHub repo.\n",
    "both_nights=False\n",
    "#both_nights=True\n",
    "#Then define a bunch of filenames:\n",
    "importlib.reload(imagehandler)\n",
    "filename = '../dev_data/2015RS281_HSC20160826_112.fits'\n",
    "if both_nights:\n",
    "    filenames=[filename.replace('100', str(i)) for i in np.arange(100, 124)]\n",
    "    filenames[-12:]=[filenamei.replace('0825', '0826') for filenamei in filenames[-12:]]\n",
    "else:\n",
    "    filenames=[filename.replace('112', str(i)) for i in np.arange(112, 124)]\n",
    "\n",
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(imagehandler)\n",
    "D=imagehandler.DataHandler(filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initialization can be given the same additional keywords as DataEnsemble. \n",
    "\n",
    "The content of _D_ is the list of filenames, the list of extension numbers, and then three DataEnsemble objects for storing the _image_data_ , _shifted_data_ and _stacked_data_, which all look like the DataEnsemble object _E_ above, although the latter two start out empty. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('D:',[key for key in D.__dict__.keys()])\n",
    "print('D.image_data:', [key for key in D.image_data.__dict__.keys()])\n",
    "print('D.shifted_data:', [key for key in D.stacked_data.__dict__.keys()])\n",
    "print('D.stacked_data:', [key for key in D.stacked_data.__dict__.keys()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's stack the non-shifted images, both mean and median stacking. Mean is better as it preserves photometric accuracy, but sometimes median is nice to look at. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#D.stack(shifted=False, save_to_filename='mean_stack.fits')\n",
    "D.stack(shifted=False)\n",
    "print(D.stacked_data.data.min())\n",
    "plt.imshow((D.stacked_data.data-D.stacked_data.data.min())[520:720,405:605], origin='lower', cmap='gray',norm=LogNorm())\n",
    "cbar = plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#D.stack(shifted=False, median_combine=True, save_to_filename='median_stack.fits')\n",
    "D.stack(shifted=False, median_combine=True)\n",
    "plt.imshow((D.stacked_data.data-D.stacked_data.data.min())[520:720,405:605], origin='lower', cmap='gray',norm=LogNorm())\n",
    "cbar = plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now define some an array of shifts and shift the data. _.integer_shift_ can take a _padmean=True_ keyword to pad the shifted data with the mean value instead of NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Different shifts whether we're using 12 or 24 images:\n",
    "if both_nights:\n",
    "    shifts=np.array([620, 505]) - np.array([np.concatenate([np.linspace(253, 329, 12),\n",
    "                                                            np.linspace(542, 620, 12)]),\n",
    "                                            np.concatenate([np.linspace(288, 332, 12),\n",
    "                                                            np.linspace(459, 505, 12)])]\n",
    "                                           ).round(0).astype(int).T\n",
    "else:\n",
    "    shifts=np.array([620, 505]) - np.array([np.linspace(542, 620, 12),\n",
    "                                            np.linspace(459, 505, 12)]\n",
    "                                           ).round(0).astype(int).T\n",
    "print(shifts)\n",
    "D.integer_shift(shifts, padmean=True)\n",
    "#D.integer_shift(shifts, padmean=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_D.shifted_data_ now contains the shifted image array, which is slightly larger than the original so as to not cut out anything:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(D.image_data.data.shape, D.image_data.WCS.shape, np.shape(D.image_data.header))\n",
    "print(D.shifted_data.data.shape, D.shifted_data.WCS.shape, np.shape(D.shifted_data.header))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now stack and save, both mean and median stacking. Again, mean is better for photometric properties, but median removes more of the star signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#D.stack(shifted=True, save_to_filename='shifted_mean_stack.fits')\n",
    "D.stack(shifted=True)\n",
    "plt.imshow((D.stacked_data.data-np.nanmin(D.stacked_data.data))[520:720,405:605], origin='lower', cmap='gray',norm=LogNorm())\n",
    "cbar = plt.colorbar()\n",
    "print(np.max((D.stacked_data.data-np.nanmin(D.stacked_data.data))[520:720,405:605]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#D.stack(shifted=True, median_combine=True, save_to_filename='shifted_median_stack.fits')\n",
    "D.stack(shifted=True, median_combine=True)\n",
    "plt.imshow((D.stacked_data.data-np.nanmin(D.stacked_data.data))[520:720,405:605], origin='lower', cmap='gray',norm=LogNorm())\n",
    "cbar = plt.colorbar()\n",
    "print(np.max((D.stacked_data.data-np.nanmin(D.stacked_data.data))[520:720,405:605]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "This is just an experiment. One can subtrack the mean non-shifted image from each image before shifting and median-combining for even better cleaning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "D=imagehandler.DataHandler(filenames)\n",
    "D.stack(shifted=False, median_combine=False)\n",
    "D.image_data.data=np.array([D.image_data.data[i]-D.stacked_data.data for i in np.arange(len(D.image_data.data))])\n",
    "D.integer_shift(shifts, padmean=True)\n",
    "D.stack(shifted=True, median_combine=True, save_to_filename='shifted_median_stack_clean.fits')\n",
    "plt.imshow((D.stacked_data.data-np.nanmin(D.stacked_data.data))[520:720,405:605], origin='lower', cmap='gray',norm=LogNorm())\n",
    "cbar = plt.colorbar()\n",
    "print(np.max((D.stacked_data.data-np.nanmin(D.stacked_data.data))[520:720,405:605]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shift & Stacking a known object!\n",
    "Here is a demonstration of the D._calculate_shifts_from_known method and the D.shift_stack_by_name method.\n",
    "\n",
    "First, a demo of how D.calculate_shifts_from_known can be used to calculate the shifts for a known object (2015 RS281, a TNO), which can then be used to shift and stack the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "importlib.reload(imagehandler)\n",
    "D=imagehandler.DataHandler(filenames)\n",
    "shifts = D._calculate_shifts_from_known(object_name='2015 RS281', obs_code='568')\n",
    "print(shifts)\n",
    "D.integer_shift(shifts, padmean=True)\n",
    "D.stack(shifted=True, median_combine=True)\n",
    "plt.imshow((D.stacked_data.data-np.nanmin(D.stacked_data.data))[520:720,405:605], origin='lower', cmap='gray',norm=LogNorm())\n",
    "cbar = plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, even simpler, with the D.shift_stack_by_name method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "importlib.reload(imagehandler)\n",
    "D=imagehandler.DataHandler(filenames)\n",
    "D.stack(shifted=False, median_combine=False)\n",
    "D.image_data.data=np.array([D.image_data.data[i]-D.stacked_data.data for i in np.arange(len(D.image_data.data))])\n",
    "D.shift_stack_by_name('2015 RS281', obs_code='568', padmean=True, median_combine=True)\n",
    "D.save_stack('shift+stack_along_2015_RS281.fits')\n",
    "plt.imshow((D.stacked_data.data-np.nanmin(D.stacked_data.data))[520:720,405:605], origin='lower', cmap='gray',norm=LogNorm())\n",
    "cbar = plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a different object (2008 SV52, an asteroid):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "importlib.reload(imagehandler)\n",
    "D=imagehandler.DataHandler(filenames)\n",
    "D.stack(shifted=False, median_combine=False)\n",
    "D.image_data.data=np.array([D.image_data.data[i]-D.stacked_data.data for i in np.arange(len(D.image_data.data))])\n",
    "D.shift_stack_by_name('2008 SV52', obs_code='568', padmean=True, median_combine=True)\n",
    "D.save_stack('shift+stack_along_2008_SV52.fits')\n",
    "plt.imshow((D.stacked_data.data-np.nanmin(D.stacked_data.data))[3122:3322, 2088:2288], origin='lower', cmap='gray',norm=LogNorm())\n",
    "cbar = plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source Extractor Wrapper in Python (SEWPy)\n",
    "Just a little playing around with _sewpy_. This should not go here in the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sewpy\n",
    "import importlib\n",
    "importlib.reload(sewpy)\n",
    "sew = sewpy.SEW(sexpath='sex',\n",
    "                params=[\"X_IMAGE\", \"Y_IMAGE\", \"FLUX_AUTO\", \"FLUXERR_AUTO\", \"SNR_WIN\",\n",
    "                        \"FWHM_IMAGE\", \"ELONGATION\", \"ISOAREAF_IMAGE\", \"FLAGS\", \"NUMBER\"],\n",
    "                config={\"DETECT_MINAREA\":10, \"DETECT_THRESH\":2.5, \"ANALYSIS_THRESH\":1.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "out = sew(\"shifted_median_stack_clean.fits\")\n",
    "out[\"table\"] # this is an astropy table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, it's clearly pretty easy to get a SourceExtractor catalogue that has a very limited number of detections, of which only the known object has FLAGS==0. These are the flag bits:\n",
    "\n",
    "    1\taperture photometry is likely to be biased by neighboring sources or\n",
    "        by more than 10% of bad pixels in any aperture\n",
    "    2\tthe object has been deblended\n",
    "    4\tat least one object pixel is saturated\n",
    "    8\tthe isophotal footprint of the detected object is truncated (too close to an image boundary)\n",
    "    16\tat least one photometric aperture is incomplete or corrupted (hitting buffer or memory limits)\n",
    "    32\tthe isophotal footprint is incomplete or corrupted (hitting buffer or memory limits)\n",
    "    64\ta memory overflow occurred during deblending\n",
    "    128\ta memory overflow occurred during extraction\n",
    "\n",
    "So FLAGS==3 means both flags 1+2 apply. Anything with 2 or 3 is certainly bad, as it indicates it has found multiple sources right up against each other, so probably star/galaxy noise. I think anything with a 2 (or sum of 2 + other flag) can safely be ignored. Also, the detections can be filtered by ELONGATION and FWHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=[(bin(o['FLAGS'])[-2]!='1') & (o['ELONGATION']<2) for o in out['table']]\n",
    "good_sources=out['table'][idx]\n",
    "good_sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There, easy peasy, get the source and nothing else :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Junk & testing\n",
    "These things are here mostly as a reminder to myself about some of the functionality of various packages/classes that might be helpful to take advantage of. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A CCDData object can easily be constructed, as so:\n",
    "dat = CCDData(one.data, wcs=one.WCS, header=one.header, unit='adu')\n",
    "dat.header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wcs_reproject can take larger orders and a target_shape. \n",
    "# target_shape might be useful for preserving all the data, rather than trimming it to fit\n",
    "# inside the shape of the target WCS. Need to investigate\n",
    "reprojected_image=wcs_project(dat, E.WCS[0], order='bilinear', target_shape=(5000,5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E.WCS[0].all_pix2world([1,2,3], [1,1,1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The centre pixels of a WCS can easily be changed, like so:\n",
    "# This might be useful for propagating the WCS to the shift+stacked images,\n",
    "# as those have a margin added to them, changing the center coordinate.\n",
    "print(E.WCS[2])\n",
    "E.WCS[1].wcs.crpix=(100,100)\n",
    "print(E.WCS[2])\n",
    "# NAXIS might also need to be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E.stack(shifted=True, median_combine=True, save_to_filename='tst.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "E.save_stack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ie. we are not limited by writing files to disk. The shifting and especially the stacking is the time consuming part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#E.stack(shifted=False, save_to_filename='mean_stack.fits')\n",
    "E.stack(shifted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "stack = E.data.mean(0)\n",
    "print(np.shape(stack))\n",
    "#plt.imshow((E.stacked_data-E.stacked_data.min())[520:720,405:605], origin='lower', cmap='gray',norm=LogNorm())\n",
    "#cbar = plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "stack = np.median(E.data, 0)\n",
    "print(np.shape(stack))\n",
    "#plt.imshow((E.stacked_data-E.stacked_data.min())[520:720,405:605], origin='lower', cmap='gray',norm=LogNorm())\n",
    "#cbar = plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep=[CCDData(E.data[0], unit='adu'), CCDData(E.data[1], unit='adu'), CCDData(E.data[2], unit='adu')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(CCDData(E.data[0], unit='adu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CCDData(E.data[0], unit='adu').data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CCDData(E.data, wcs1=E.WCS, unit='adu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(CCDData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E.MJD.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E.extno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one.header['SIMPLE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one.header['ABCD']=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one.header.append(('ABCDEf', False, 'test'),end=False)\n",
    "one.header['COMMENT']=('S_MJD was set from MJD_STR')\n",
    "one.header['S_MJD']=('asdfg','hjkl')\n",
    "one.header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one.header['asdfghjkl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E.WCS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one.header_keywords.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one.key_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, use in one.header_keywords.items():\n",
    "    print()\n",
    "    print(f'SHIFTY_{key} derived from {use}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in one.header_keywords.items():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one.header['S_MJD']=one.header['CUNIT2A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one.header.comments['NAXIS1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy import wcs\n",
    "wcs.WCS(one.header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one.header['COMMENTS']='asda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one.header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datetime.datetime.today())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    (f'SHIFTY_MJD_MID derived from '\n",
    "     f'{one.header_keywords[\"MJD_START\"]} and {one.header_keywords[\"EXPTIME\"]}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one.header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one.header['COMMENT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagehandler.ImageEnsemble()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if None:\n",
    "    print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target=10\n",
    "len(f'Data reprojected to WCS of file {target} at {str(datetime.datetime.today())[:19]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shifts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_stack(DataEnsembleObject, filename='stack.fits'):\n",
    "        '''\n",
    "        Save a stack to a fits file.\n",
    "        '''\n",
    "        print(f'Saving stack to file {filename}')\n",
    "        hdu = fits.PrimaryHDU(DataEnsembleObject.data)\n",
    "        hdu.writeto(filename, overwrite=True)\n",
    "        print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdu=fits.PrimaryHDU(data=E.shifted_data[0], header=one.header)\n",
    "hdu.writeto('test.fits', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(fits.PrimaryHDU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E.WCS[0].to_header()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one.header['BP_7_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(one.WCS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one.WCS.to_header(relax=True)['CD*']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(hdu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdu[0].header['CD1_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one.header.update(E.WCS[5].to_header(relax=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wcs.WCS(one.header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E.WCS[5].to_header(relax=True)['CD*']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one.header['CD*']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdu[0].header['CD*']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one.header0.update(hdu[0].header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in one.WCS.items():\n",
    " print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one.header0['CD*']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E.WCS[0].to_header(relax=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one.header['CD*_*']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del one.header['CD2_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one.header['CD*']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdu=E.WCS[5].to_fits(relax=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdu[0].header['CD*']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "two=copy.deepcopy(one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two.header['CD*']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two.header.update(E.WCS[5].to_header(relax=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two.header['CD*']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one.header['CD*']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del one.header['CD*']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one.header['CD?_?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h=E.WCS[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h=E.WCS[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E.WCS[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E.WCS[4].wcs.crpix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E.WCS[4].wcs.crpix += (1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E.WCS[4].wcs.crpix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = str(datetime.today())[:19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=5\n",
    "ymax = shifts[:, 0].max()\n",
    "xmax = shifts[:, 1].max()\n",
    "pad_size = ((shifts[i, 0], ymax - shifts[i, 0]),  # Size of pad\n",
    "                        (shifts[i, 1], xmax - shifts[i, 1]))  # on 4 sides\n",
    "\n",
    "com_str = (f'At {now} data was padded by {pad_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(com_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(len(E.WCS)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance('123',str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "which_WCS='drgd'\n",
    "wcsidx=0 if which_WCS.lower()=='first' else -1 if which_WCS.lower()=='last' else 5\n",
    "print(wcsidx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(E.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(E.WCS) == ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='data.fits'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'fits' in filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(one.data.shape)==2\n",
    "x=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename.replace('.fits',f'_{1234:05.0f}.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(fits.PrimaryHDU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one.header[:]=one.header['SIMPLE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one.header[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
